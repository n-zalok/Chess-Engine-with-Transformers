{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "696fd121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"noor-zalouk/tournament-chess-games-modified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9061a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, ds, tokenizer, label_to_id, max_length):\n",
    "        self.ds = ds\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_to_id = label_to_id\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = '[CLS]' + ' ' + self.ds[idx]['positions']\n",
    "        input_ids = [self.tokenizer[word] for word in text.split()]\n",
    "        input_ids = input_ids[:self.max_length]\n",
    "\n",
    "        if self.ds[idx]['moves'] in ['e1g1', 'e8g8', 'e1c1', 'e8c8']:\n",
    "            start_labels = self.label_to_id[self.ds['moves'][idx]]\n",
    "            end_labels = start_labels\n",
    "        else:\n",
    "            start_labels = self.label_to_id[self.ds[idx]['moves'][0:2]]\n",
    "            end_labels = self.label_to_id[self.ds[idx]['moves'][2:4]]\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'start_labels': torch.tensor(start_labels, dtype=torch.long),\n",
    "            'end_labels': torch.tensor(end_labels, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d603ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import architecture as arch\n",
    "\n",
    "config = arch.Config()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tokenizer = arch.tokenizer\n",
    "label_to_id = arch.label_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e14fbe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "model = arch.ChessMoveClassifier(config, device)\n",
    "model.to(device)\n",
    "\n",
    "batch_size = 128\n",
    "gradient_accumulation_steps = 1\n",
    "epochs = 15\n",
    "lr = 8e-4\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_set = ChessDataset(ds['train'], tokenizer, label_to_id, config.max_position_embeddings)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_set = ChessDataset(ds['valid'], tokenizer, label_to_id, config.max_position_embeddings)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "\n",
    "# Scheduler setup\n",
    "num_update_steps_per_epoch = len(train_loader) // gradient_accumulation_steps\n",
    "num_training_steps = num_update_steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1 * num_training_steps)  # 10% warmup\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bddb35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_loss = 0\n",
    "    total_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            start_labels = batch['start_labels'].to(device)\n",
    "            end_labels = batch['end_labels'].to(device)\n",
    "\n",
    "            start_logits, end_logits = model(input_ids=input_ids)\n",
    "            loss_start = criterion(start_logits, start_labels)\n",
    "            loss_end = criterion(end_logits, end_labels)\n",
    "            loss = (loss_start + loss_end) / 2\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "\n",
    "    avg_val_loss = total_loss / total_batches\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cacbd182",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 17:07:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/19 17:07:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Train Loss: 3.0261, Validation Loss: 2.4235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 18:04:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/19 18:04:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15 - Train Loss: 2.4564, Validation Loss: 2.2156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 19:02:25 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/19 19:02:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15 - Train Loss: 2.3035, Validation Loss: 2.1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 19:57:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/19 19:57:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15 - Train Loss: 2.2260, Validation Loss: 2.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 20:54:22 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/19 20:54:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15 - Train Loss: 2.1766, Validation Loss: 2.0087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 21:51:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/19 21:51:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15 - Train Loss: 2.1399, Validation Loss: 1.9765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 22:46:39 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/19 22:46:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15 - Train Loss: 2.1106, Validation Loss: 1.9494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/19 23:41:26 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/19 23:41:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15 - Train Loss: 2.0859, Validation Loss: 1.9264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/20 00:36:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/20 00:36:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15 - Train Loss: 2.0626, Validation Loss: 1.9006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/20 01:31:09 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/20 01:31:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/15 - Train Loss: 2.0411, Validation Loss: 1.8879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/20 02:25:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/20 02:25:59 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/15 - Train Loss: 2.0205, Validation Loss: 1.8645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/20 03:20:46 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/20 03:20:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15 - Train Loss: 1.9997, Validation Loss: 1.8507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/20 04:15:31 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/20 04:15:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/15 - Train Loss: 1.9801, Validation Loss: 1.8303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/20 05:10:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/20 05:10:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/15 - Train Loss: 1.9601, Validation Loss: 1.8110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/08/20 06:07:56 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "\u001b[31m2025/08/20 06:08:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/15 - Train Loss: 1.9432, Validation Loss: 1.8023\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params({\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"initial_lr\": lr,\n",
    "        \"gradient_accumulation_steps\": gradient_accumulation_steps,\n",
    "        \"num_warmup_steps\": num_warmup_steps,\n",
    "        \"config\": config.to_dict()\n",
    "    })\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        total_batches = 0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch}/{epochs}\", leave=False)\n",
    "        for step, batch in enumerate(loop):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            start_labels = batch['start_labels'].to(device)\n",
    "            end_labels = batch['end_labels'].to(device)\n",
    "\n",
    "            start_logits, end_logits = model(input_ids=input_ids)\n",
    "            loss_start = criterion(start_logits, start_labels)\n",
    "            loss_end = criterion(end_logits, end_labels)\n",
    "            loss = (loss_start + loss_end) / 2\n",
    "\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "            loss.backward()\n",
    "\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_batches += 1\n",
    "            loop.set_postfix(loss=loss.item(), lr=scheduler.get_last_lr()[0])\n",
    "\n",
    "        train_loss = total_loss / total_batches\n",
    "        valid_loss = evaluate(model, valid_loader, device)\n",
    "\n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": valid_loss,\n",
    "            \"lr\": scheduler.get_last_lr()[0]\n",
    "        }, step=epoch)\n",
    "\n",
    "        # Save model checkpoint with MLflow\n",
    "        mlflow.pytorch.log_model(model, f\"chess-epoch-{epoch}\")\n",
    "        print(f\"Epoch {epoch}/{epochs} - Train Loss: {train_loss:.4f}, Validation Loss: {valid_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd4d5d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a69d0b4b124ca08ce0d207a681e733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a13b91f4d624bc5a9c8bce0b4c08ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ChessMoveClassifier(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (embeddings): Embeddings(\n",
       "      (token_embeddings): Embedding(20, 128)\n",
       "      (position_embeddings): Embedding(68, 128)\n",
       "      (layer_norm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (layer_norm_1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): MultiHeadAttention(\n",
       "          (heads): ModuleList(\n",
       "            (0-3): 4 x AttentionHead(\n",
       "              (q): Linear(in_features=128, out_features=32, bias=True)\n",
       "              (k): Linear(in_features=128, out_features=32, bias=True)\n",
       "              (v): Linear(in_features=128, out_features=32, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (output_linear): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): FeedForward(\n",
       "          (linear_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (linear_2): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (start_head): Linear(in_features=128, out_features=66, bias=True)\n",
       "  (end_head): Linear(in_features=128, out_features=66, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace with the actual run_id from MLflow\n",
    "run_id = \"0e8284ddafe4494099b88c7c85725df7\"\n",
    "artifact_path = \"chess-epoch-15\"  # path you logged under\n",
    "\n",
    "model_loaded = mlflow.pytorch.load_model(f\"runs:/{run_id}/{artifact_path}\")\n",
    "model_loaded.to(device)\n",
    "model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd8a13a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_loaded.state_dict(), \"chess_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "452dda0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipe\n",
    "import chess\n",
    "\n",
    "board = chess.Board()\n",
    "input = pipe.prepare_input(board)\n",
    "input = input.unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cb7103a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  4,  6, 11,  9, 10, 12, 13, 10,  9, 11,  8,  8,  8,  8,  8,  8,\n",
       "          8,  8,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "          7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7, 14, 14,\n",
       "         14, 14, 14, 14, 14, 14, 17, 15, 16, 18, 19, 16, 15, 17]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "743b70b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ -0.2780,   0.9939,  -2.5925,   0.0333,  -6.8306,  -5.6342,  -6.0418,\n",
       "           -5.6006,   3.9611,   5.6951,  -2.5400,  -4.5057,  -1.8292,  -4.9075,\n",
       "           -4.5986,  -6.2393,   3.0092,   9.1952,  -1.0495,  -3.6861,  -2.1646,\n",
       "           -5.9491,  -4.2649,  -8.5509,   0.9781,  10.6924,   2.9767,  -7.2969,\n",
       "           -0.1877,  -7.8628,  -3.8501,  -5.3964,  -0.6315,  10.9902,   1.4613,\n",
       "           -6.5034,  -0.5225,  -7.2955,  -4.8630,  -6.2635,   2.6128,   2.2747,\n",
       "           -1.1401,  -2.1958,   1.1575,  -4.4839,  -5.8524,  -8.3616,   9.3948,\n",
       "            5.2283,  -3.1537,  -2.1141,  -5.0036,  -4.0353,  -6.4315,  -4.5495,\n",
       "           -4.6077,   1.6003,  -1.5516,  -2.3726,  -1.7077, -11.0678,  -4.8503,\n",
       "           -9.0453,  -2.0666,  -2.7445]], device='cuda:0',\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor([[-5.9376, -2.6215,  0.3279, -0.5883, -2.5371, -4.7404, -5.1698, -4.6630,\n",
       "          -2.0081, -2.0776,  4.5738,  1.2005, -0.7996, -5.6397, -3.4416, -6.6084,\n",
       "          -2.7797, -1.7720,  3.7100,  7.9203, -3.5795, -2.1167, -5.8601, -4.1633,\n",
       "          -0.3471, -3.2039,  1.3932,  9.6350, -1.8123, -3.7365, -5.8723, -5.5993,\n",
       "          -1.5988, -1.4417,  2.3120,  9.8814, -0.5847, -3.3188, -6.0526, -5.3028,\n",
       "          -0.1823, -2.5252,  8.1093,  2.6824, -4.7339, -2.9403, -3.8683, -4.5545,\n",
       "          -8.8443, -1.9262,  3.2931,  0.3719,  1.2188, -5.4868, -5.2568, -7.6010,\n",
       "          -3.8411, -2.2828, -0.4158, -0.1955, -3.6783, -1.2207, -4.5581, -5.6299,\n",
       "          -3.3071, -4.4165]], device='cuda:0', grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model_loaded(input)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e726195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[33, 25, 48, 17,  9, 49,  8, 16, 26, 40, 41, 57, 34, 44,  1, 24,  3, 28,\n",
       "          0, 36, 32, 18, 42, 58, 60, 12, 64, 51, 20, 43, 59, 10,  2, 65, 50, 19,\n",
       "         30, 53, 22, 45, 11, 55, 14, 56, 62, 38, 13, 52, 31,  7,  5, 46, 21,  6,\n",
       "         15, 39, 54, 35,  4, 37, 27, 29, 47, 23, 63, 61]], device='cuda:0')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(output[0], k=output[0].size(1) ,dim=-1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff8d65f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
